{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "import html5lib\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping - read html and Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for scraping director pages on Rotten Tomatoes \n",
    "\n",
    "tbls1 = pd.read_html(\"http://www.rottentomatoes.com/celebrity/wes_anderson\")\n",
    "tbls1 = tbls1[1]\n",
    "tbls1[\"Name\"] = \"Wes Anderson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#appending scraped pages and creating df\n",
    "frames = [tbls1, tbls2, tbls3, tbls4, tbls5, tbls6, tbls7, tbls8, tbls9, tbls10, tbls11, tbls12, tbls13, tbls14, tbls15, tbls16,\n",
    "         tbls17,tbls18,tbls19,tbls20]\n",
    "\n",
    "df = pd.concat(frames)\n",
    "df[\"MOVIECOUNT\"] = 1\n",
    "cols = [\"RATING\", \"TITLE\", \"CREDIT\", \"BOX OFFICE\", \"YEAR\", \"NAME\", \"MOVIECOUNT\"]\n",
    "df.columns = cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Munging\n",
    "Each function in the below cell counts a 0 or a 1 if it detects the needed word in the 'credits' cell from Rotten Tomatoes. These words are always spelled correctly. To handle the actor column, I wanted to be sure not to pick up any cameos (which often include the name 'man on a train...' or 'cameo' or 'himself'. Since speaking roles were what I was after, I cleaned out the rest of the cell contents and if anything was left after trimming the fat, I counted that as a character name. In this situation, it helped to 'know' my data / to have a small enough dataframe to be able to see patterns in cameo names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['RATING'] = pd.DataFrame.replace(df['RATING'], to_replace= np.nan, value = 0)\n",
    "df[\"RATING\"] = df[\"RATING\"].map(lambda x: str(x)[:2])\n",
    "df[\"RATING\"] = df[\"RATING\"].map(lambda x: re.sub('[^0-9]','', x))\n",
    "\n",
    "df['DIRECTOR'] = 0\n",
    "df['PRODUCER'] = 0\n",
    "df['EXECUTIVEPRODUCER'] = 0\n",
    "df['ACTOR'] = 0\n",
    "df['WRITER'] = 0\n",
    "df[\"CAMEO\"] = 0\n",
    "\n",
    "def director(credit):\n",
    "    if re.search(\"Director\", credit):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "    \n",
    "def producer(credit):\n",
    "    if re.search(\"Executive\", credit):\n",
    "        return(0)\n",
    "    elif re.search(\"Producer\", credit):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "def eproducer(credit):\n",
    "    if re.search(\"Executive Producer\", credit):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "def writer(credit):\n",
    "    if re.search(\"Screenwriter\", credit):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "\n",
    "def cameo(credit):\n",
    "    if re.search(\"Actor\", credit):\n",
    "        return(1)\n",
    "    elif re.search(\"Man\", credit):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)\n",
    "    \n",
    "def actor(credit):\n",
    "    if re.search(\"Man\", credit):\n",
    "        return(0)\n",
    "    else: \n",
    "        if re.sub(\"Executive\", \"\", re.sub(\"Director\", \"\", \n",
    "                                      re.sub(\"Screenwriter\", \"\", \n",
    "                                             re.sub(\"Producer\", \"\", \n",
    "                                                    re.sub(\"Actor\", \"\", \n",
    "                                                           re.sub(\"Himself\", \"\", credit)))))).strip() != \"\":\n",
    "            return(1)\n",
    "        else:\n",
    "            return(0)\n",
    "\n",
    "df['DIRECTOR'] = df['CREDIT'].apply(director)\n",
    "df['ACTOR'] = df['CREDIT'].apply(actor)\n",
    "df['CAMEO'] = df['CREDIT'].apply(cameo)\n",
    "df['PRODUCER'] = df['CREDIT'].apply(producer)\n",
    "df['EXECUTIVEPRODUCER'] = df['CREDIT'].apply(eproducer)\n",
    "df['WRITER'] = df['CREDIT'].apply(writer)\n",
    "df[\"LIT\"] = df[\"EXECUTIVEPRODUCER\"] + df[\"WRITER\"] + df[\"PRODUCER\"] + df[\"ACTOR\"]\n",
    "df[\"RATING\"] = df[\"RATING\"].map(lambda x: int(x))\n",
    "df = df[df[\"DIRECTOR\"] > 0] #removes movies from director pages where they didn't direct\n",
    "df = df[df[\"RATING\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.to_pickle(df, \"directors.pickle\") #storing progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is scraped information from a metis classmate!\n",
    "p = \"df_all.pickle\"\n",
    "janine = pd.read_pickle(p)\n",
    "cols = ['BUDGET', 'CLOSEDATE', 'DIST', 'DOMESTICGROSS', 'FOREIGNCROSS', 'GENRE','INRELEASE', 'MPAA', \n",
    "        'RELEASEDATE', 'RUNTIME', 'TITLE', 'WIDEST', 'LINK']\n",
    "\n",
    "janine.columns = cols\n",
    "janine = pd.to_pickle(janine, \"df_all.pickle\")\n",
    "janine = \"df_all.pickle\"\n",
    "janine = pd.read_pickle(janine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining dataframes from different sources, pickling for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nudf = pd.merge(df, pickle, on=\"TITLE\")\n",
    "cols = ['RATING', 'TITLE', 'CREDIT', 'BOXOFFICE', 'YEAR', 'NAME', 'MOVIECOUNT',\n",
    "       'DIRECTOR', 'PRODUCER', 'EXECUTIVEPRODUCER', 'ACTOR', 'WRITER', 'CAMEO',\n",
    "       'LIT', 'BUDGET', 'CLOSEDATE', 'DIST', 'DOMESTICGROSS', 'FOREIGNCROSS',\n",
    "       'GENRE', 'INRELEASE', 'MPAA', 'RELEASEDATE', 'RUNTIME', 'WIDEST',\n",
    "       'LINK']\n",
    "nudf.columns = cols\n",
    "nudf[\"BUDGET\"] = pd.DataFrame.replace(nudf[\"BUDGET\"], to_replace= np.nan, value = 0)\n",
    "nudf[\"BOXOFFICE\"] = nudf[\"BOXOFFICE\"].map(lambda x: re.sub('[^0-9]','', x)) #removing non-integers\n",
    "nudf[\"BOXOFFICE\"] = pd.DataFrame.replace(nudf[\"BOXOFFICE\"], to_replace= \"\", value = 0) #handling blanks will be removed\n",
    "nudf[\"BOXOFFICE\"] = nudf[\"BOXOFFICE\"].map(lambda x: int(x))\n",
    "nudf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combining pickles\n",
    "nudf = nudf[nudf[\"BOXOFFICE\"] > 0]\n",
    "nudf = pd.to_pickle(nudf, \"full_luther.pickle\")\n",
    "nudf = \"full_luther.pickle\"\n",
    "nudf = pd.read_pickle(nudf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - OSL\n",
    "I tried a few different tactics - ultimately I decided to create interactions between the various LIT categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#another dataframe from a generous classmate\n",
    "rafa = pd.read_pickle(\"rtscrapedgood.pkl\")\n",
    "rafa.columns  = ['TITLE', 'YR', 'YR2', 'URL', 'CRITICSCORE',\n",
    "       'AUDIENCESCORE']\n",
    "nudf = pd.merge(nudf, rafa, how=\"inner\", on=\"TITLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nudf[\"ACTORPROD\"] = nudf[\"ACTOR\"] * nudf[\"PRODUCER\"]\n",
    "nudf[\"ACTOREP\"] = nudf[\"ACTOR\"] * nudf[\"EXECUTIVEPRODUCER\"]\n",
    "nudf[\"ACTORWRIT\"] = nudf[\"ACTOR\"] * nudf[\"WRITER\"]\n",
    "nudf[\"WRITPROD\"] = nudf[\"PRODUCER\"] * nudf[\"WRITER\"]\n",
    "nudf[\"WRITEEP\"] = nudf[\"EXECUTIVEPRODUCER\"] * nudf[\"WRITER\"]\n",
    "nudf[\"FULLYOLO_EP\"] = nudf[\"ACTOR\"] * nudf[\"EXECUTIVEPRODUCER\"] * nudf[\"WRITER\"]\n",
    "nudf[\"FULLYOLO_PROD\"] = nudf[\"ACTOR\"] * nudf[\"PRODUCER\"] * nudf[\"WRITER\"]\n",
    "nudf = pd.to_pickle(\"absrottentomatos.pickle\") #pickling yet again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nudf.corr() #checking correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import seaborn as sns\n",
    "from seaborn import plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm1 = smf.ols(\"DOMESTICGROSS ~ WRITEEP + FULLYOLO_EP + FULLYOLO_PROD + BUDGET + ACTORPROD + WRITPROD\", data=nudf)\n",
    "\n",
    "fit1 = lm1.fit()\n",
    "fit1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation - Kfold, Lasso\n",
    "I suspected that I had too few data points for how many features I had. I decided to do a cross validation on my dataframe to see if this was the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import linear_model\n",
    "\n",
    "temp = nudf[[\"WRITEEP\", \"FULLYOLO_EP\", \"FULLYOLO_PROD\", \"BUDGET\", \"ACTORPROD\", \"WRITPROD\", 'AUDIENCESCORE']]\n",
    "temp = temp.fillna(value = 0)\n",
    "\n",
    "x, y = temp.iloc[:,:-1], temp[\"AUDIENCESCORE\"]\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "kf = KFold(141, n_folds = 5)\n",
    "rng = np.arange(1, 20, 1)\n",
    "alphalist = []\n",
    "SSElist = []\n",
    "for a in rng:\n",
    "    SSE = 0\n",
    "    alphalist.append(a)\n",
    "    for train_index, test_index in kf:\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        cf = linear_model.Lasso(alpha=a)\n",
    "        cf.fit(x_train, y_train)\n",
    "        y_pred = cf.predict(x_test)\n",
    "        SSE += ((y_pred - y_test) **2).sum() \n",
    "    SSE = SSE / 5\n",
    "    SSElist.append(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plotting the SSE against the lambda. \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "#lambda increases from left to right (high variance on left, high bias on right)\n",
    "#overfitting is on the right in this graph, underfit is on the left\n",
    "plt.plot(alphalist, SSElist)\n",
    "plt.xlabel(\"Lambda (alpha)\")\n",
    "plt.ylabel(\"Error\")\n",
    "\n",
    "temp2 = pd.DataFrame(SSElist, alphalist)\n",
    "cols = [\"column\"]\n",
    "temp2.columns = cols\n",
    "temp2 = temp2.sort_values(\"column\", ascending = True )\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_best = linear_model.Lasso(alpha= 4) #optimized lambda and put it in the linear model again. It decimated many of my coeffs\n",
    "model_best.fit(x_train, y_train)\n",
    "model_best.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections, next steps\n",
    "\n",
    "- I need more data\n",
    "- this is still an interesting subject, and though the observations are small, it is worth continuing to investigate\n",
    "- I need to try log transormations, especially on the gross dollar graphs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
